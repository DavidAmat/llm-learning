{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/david.amat/Documents/david/llm-learning/llm/gpt-from-scratch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "project_dir = os.path.abspath('.')\n",
    "WORK_DIR = os.path.abspath(os.path.join(project_dir, '../'))\n",
    "os.chdir(WORK_DIR)\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Download Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the tiny shakespeare dataset\n",
    "input_file_path = os.path.join(WORK_DIR, 'input.txt')\n",
    "if not os.path.exists(input_file_path):\n",
    "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "    with open(input_file_path, 'w') as f:\n",
    "        f.write(requests.get(data_url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 1,115,394\n",
      "all the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "with open(input_file_path, 'r') as f:\n",
    "    text = f.read()\n",
    "print(f\"length of dataset in characters: {len(text):,}\")\n",
    "\n",
    "# get all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", ''.join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Download Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Tik Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â trying with tiktoken to see diferences\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 4178, 612]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"hii there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.n_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Tik Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Tokenize Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Set print options to show 4 decimal places without scientific notation\n",
    "torch.set_printoptions(sci_mode=False, precision=4, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citi'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Tokenize Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train and test splits\n",
    "n = len(data)\n",
    "train_data = data[:int(n*0.9)]\n",
    "val_data = data[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [18] -> 47\n",
      "Input: [18, 47] -> 56\n",
      "Input: [18, 47, 56] -> 57\n",
      "Input: [18, 47, 56, 57] -> 58\n",
      "Input: [18, 47, 56, 57, 58] -> 1\n",
      "Input: [18, 47, 56, 57, 58, 1] -> 15\n",
      "Input: [18, 47, 56, 57, 58, 1, 15] -> 47\n",
      "Input: [18, 47, 56, 57, 58, 1, 15, 47] -> 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"Input: {context.tolist()} -> {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "        [25, 17, 27, 10,  0, 21,  1, 54]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
       "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
       "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
       "        [17, 27, 10,  0, 21,  1, 54, 39]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Pytorch Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x135541d90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from copy import copy as cp\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Simulates a embedding prediction coming from the model\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets):\n",
    "        # Simulate and embedding prediction coming from the model\n",
    "        logits = self.token_embedding_table(idx) # (Batch, Time, Channel)\n",
    "        \n",
    "        # If no targets provided, only return logits\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Flatten the Time and Channel dimensions\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "        \n",
    "            # Flatten the targets\n",
    "            targets = targets.view(B*T)\n",
    "        \n",
    "            # Loss expects (Batch, Channel, Time)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        # Explanation\n",
    "        # for a single sample:\n",
    "        # Loss = - log ( (exp(logit[y_i])) / (sum(exp(logit_i))) ) where y_i is the index of the target next character\n",
    "        # Shapes:\n",
    "        # logits: (Batch * Time, Channel) => [32, 65]\n",
    "        # targets: (Batch * Time) => [32]\n",
    "        # Example: target = 43 // logits[0, 43] = -0.1728 0 => exp(XX) = 0.8413\n",
    "        #  for the denominator: torch.sum(torch.exp(logits[0, :])) = 96.6660\n",
    "        # => Loss = - log(0.8413 / 96.6660) = 4.7441\n",
    "        \n",
    "        # For all the samples\n",
    "        # F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy Loss Formula for Batch\n",
    "\n",
    "$$\\text{CrossEntropyLoss} = \\frac{1}{B \\times T} \\sum_{i=1}^{B} \\sum_{t=1}^{T} -\\log\\left(\\frac{\\exp(\\text{logits}_{i,t,y_{i,t}})}{\\sum_{j=1}^{C} \\exp(\\text{logits}_{i,t,j})}\\right)\n",
    "$$\n",
    "\n",
    "By default, the losses are averaged over each loss element in the batch. Otherwise provide `size_average` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BiGramLanguageModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 65])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.token_embedding_table.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 65])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = m.token_embedding_table(xb)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = logits.shape\n",
    "logits = logits.view(B*T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = cp(yb)\n",
    "targets = targets.view(B*T)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8786, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flogits, floss = m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8786, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Pytorch Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Generate sequence from Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Simulates a embedding prediction of the next character after the given token (idx)\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # Simulate and embedding prediction coming from the model\n",
    "        # idx => (Batch, Time) values are character index\n",
    "        logits = self.token_embedding_table(idx) # => (Batch, Time, Channel) # values are logits for each character\n",
    "        \n",
    "        # If no targets provided, only return logits\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Flatten the Time and Channel dimensions\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "        \n",
    "            # Flatten the targets\n",
    "            targets = targets.view(B*T)\n",
    "        \n",
    "            # Loss expects (Batch, Channel, Time)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx => [B, T]\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Calling without targets => only logits with B,T,C shape\n",
    "            logits, _ = self(idx)\n",
    "            \n",
    "            # Get the last time step (T=last) => [B, C]\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1) # => [B, C]\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # => [B, 1]\n",
    "            \n",
    "            # Add to idx the generated token\n",
    "            # # idx => [B, T] + [B, 1] => [B, T+1]\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[0.1, 1, 6], [0.1, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "# Returns the indices of a sampling considering the values of a as logits \n",
    "# (the higher the value, the higher the probability of being sampled)\n",
    "torch.multinomial(a, num_samples=15, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BiGramLanguageModel(vocab_size)\n",
    "flogits, floss = m(xb)\n",
    "\n",
    "# Get the last timestep\n",
    "lflogits = flogits[:, -1, :] # B, C\n",
    "\n",
    "fprobs = F.softmax(lflogits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 65])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_next = torch.multinomial(fprobs, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_next.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30],\n",
       "        [54],\n",
       "        [30],\n",
       "        [23]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39,  1, 46, 39])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 43, 58,  5, 57,  1, 46, 43, 30],\n",
       "        [44, 53, 56,  1, 58, 46, 39, 58, 54],\n",
       "        [52, 58,  1, 58, 46, 39, 58,  1, 30],\n",
       "        [25, 17, 27, 10,  0, 21,  1, 54, 23]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Concatenation of the generated idx (idx_next) to the original input (xb)\n",
    "torch.cat((xb, idx_next), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Generate sequence from Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Try the generator of sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BiGramLanguageModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_init = torch.zeros((1,1), dtype=torch.long)\n",
    "gen = m.generate(idx=t_init, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnZnZt.vr,E'':CpBxFNYWFgzv?;M!cPNQUw.Kg$ &gMkioP.nrDQ\\nfdpepBDOTwHtkwumsS3-u.x-&zu?$Lglwqq$KjRrQiYb B,\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(gen[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Try the generator of sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Train Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: 4.67943000793457\n",
      "Step: 1000 Loss: 3.673828125\n",
      "Step: 2000 Loss: 3.024789571762085\n",
      "Step: 3000 Loss: 2.6680943965911865\n",
      "Step: 4000 Loss: 2.7315430641174316\n",
      "Step: 5000 Loss: 2.521266222000122\n",
      "Step: 6000 Loss: 2.639226198196411\n",
      "Step: 7000 Loss: 2.5043129920959473\n",
      "Step: 8000 Loss: 2.4675230979919434\n",
      "Step: 9000 Loss: 2.4043755531311035\n",
      "Step: 10000 Loss: 2.428785562515259\n",
      "Step: 11000 Loss: 2.329158067703247\n",
      "Step: 12000 Loss: 2.6495845317840576\n",
      "Step: 13000 Loss: 2.573981285095215\n",
      "Step: 14000 Loss: 2.5653419494628906\n",
      "Step: 15000 Loss: 2.452608108520508\n",
      "Step: 16000 Loss: 2.42024564743042\n",
      "Step: 17000 Loss: 2.4490718841552734\n",
      "Step: 18000 Loss: 2.319751501083374\n",
      "Step: 19000 Loss: 2.5759243965148926\n",
      "Step: 19999 Loss: 2.5398643016815186\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(20000):\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # Evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    \n",
    "    # Training step\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print every 1000 steps\n",
    "    if steps % 1000 == 0:\n",
    "        print(f\"Step: {steps} Loss: {loss.item()}\")        \n",
    "    \n",
    "print(f\"Step: {steps} Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAla ancade ted ELondiserdoundd?\\nT:\\nMitho yonteam s? ouiearsithe ghormm l beritold KI:\\n\\ne IChieeng ng'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate\n",
    "t_init = torch.zeros((1,1), dtype=torch.long)\n",
    "gen = m.generate(idx=t_init, max_new_tokens=100)\n",
    "decode(gen[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Train Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Trick on self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate a simple attention like averaging for time (t) all the previous embeddings up until t of that sequence in that batch (no look at the afterwards t+1, t+2, etc...) (masked self-attention simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]  # [t, C]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xprev.shape # [t=8, C=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.0894)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.1808, -0.3596]) # which matches -0.0894 of the xbow second row first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.14900000000000002)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.1808, -0.3596, 0.6258]) # which matches -0.0894 of the xbow second row first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Trick on self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Trick on self-attention introducing TRIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tril(torch.ones(3,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "a_norm=tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c=tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "\n",
    "# Make rows normalized to sum 1\n",
    "a_norm = a / torch.sum(a, dim=1, keepdim=True)\n",
    "\n",
    "# \n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a_norm @ b\n",
    "print(f\"{a=}\\n{a_norm=}\\n{b=}\\n{c=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Trick on self-attention introducing TRIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Applying TRIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "xbow2 = wei @ x  # [T, T] @ [B, T, C] => (broadcasting automatic) [B, T, T] @ [B, T, C] => [B, T, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei.shape=torch.Size([8, 8])\n",
      "x.shape=torch.Size([4, 8, 2])\n",
      "xbow2.shape=torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{wei.shape=}\\n{x.shape=}\\n{xbow2.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Applying TRIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Applying TRIL with Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = F.softmax(wei, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow3 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Applying TRIL with Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Linear layer to project embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 32\n",
    "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "lm_head = nn.Linear(n_embd, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only 3 samples from batch\n",
    "xb1 = xb[:3,...]  #Â [3, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 32])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx and targets are both (B,T) tensor of integers\n",
    "tok_emb = token_embedding_table(xb1) # (B,T,C)\n",
    "tok_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 65])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lm_head(tok_emb) # (B,T,C)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Linear layer to project embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embedding_table = nn.Embedding(block_size, n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only 3 samples from batch\n",
    "xb1 = xb[:3,...]  #Â [3, 8]\n",
    "\n",
    "#Â Get the token embeddings\n",
    "tok_emb = token_embedding_table(xb1) # (B,T,C)\n",
    "\n",
    "# Get the position embeddings\n",
    "Txb = xb1.shape[1]\n",
    "pos_emb = position_embedding_table(torch.arange(Txb)) # (T,C)\n",
    "\n",
    "# Add the position embeddings to the token embeddings\n",
    "emb_final = tok_emb + pos_emb  # Broadcasting is done automatically (B,T,C) + (T,C) => (B,T,C) + (B,T,C) => (B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 65])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_emb_final = lm_head(emb_final) # (B,T,C)\n",
    "logits_emb_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Position embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [START] Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every single token in the sequence will emit a QUERY and a KEY vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Head\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # [B, T, H]\n",
    "q = query(x) # [B, T, H]\n",
    "v = value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.randn(2,3,4)\n",
    "print(ex.shape)\n",
    "\n",
    "# Transpose the last two dimensions\n",
    "ex.transpose(-2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affinities between keys and vectors\n",
    "# careful, the transpose to do the dot product must NOT happen at the batch dimension level\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, H ) @ (B, H, T) => (B, T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = wei @ v # (B, T, T) @ (B, T, C) => (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.5599,     0.4401,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.3220,     0.2016,     0.4764,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.1640,     0.0815,     0.2961,     0.4585,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.2051,     0.3007,     0.1894,     0.1808,     0.1241,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.0600,     0.1273,     0.0291,     0.0169,     0.0552,     0.7114,     0.0000,     0.0000],\n",
       "         [    0.1408,     0.1025,     0.1744,     0.2038,     0.1690,     0.0669,     0.1426,     0.0000],\n",
       "         [    0.0223,     0.1086,     0.0082,     0.0040,     0.0080,     0.7257,     0.0216,     0.1016]],\n",
       "\n",
       "        [[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.5634,     0.4366,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.0000,     0.0006,     0.9994,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.4492,     0.0519,     0.0008,     0.4981,     0.0000,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.2870,     0.1766,     0.0135,     0.4827,     0.0402,     0.0000,     0.0000,     0.0000],\n",
       "         [    0.0046,     0.0253,     0.7557,     0.0041,     0.0239,     0.1865,     0.0000,     0.0000],\n",
       "         [    0.2899,     0.1259,     0.0094,     0.4080,     0.0542,     0.0192,     0.0934,     0.0000],\n",
       "         [    0.2495,     0.0391,     0.0078,     0.1518,     0.2876,     0.0334,     0.1999,     0.0310]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0:2,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  -----  [START] Scaled Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "wei_norm = q @ k.transpose(-2, -1) * (head_size ** -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k.var()=1.0028 q.var()=1.0326 wei.var()=17.6690\n"
     ]
    }
   ],
   "source": [
    "print(f\"{k.var()=:.4f} {q.var()=:.4f} {wei.var()=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k.var()=0.9256 q.var()=0.9796 wei_norm.var()=0.8931\n"
     ]
    }
   ],
   "source": [
    "print(f\"{k.var()=:.4f} {q.var()=:.4f} {wei_norm.var()=:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  -----  [END] Scaled Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [END] Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [START] Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [START] Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "      # x: [B, H]\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # xmean: [1, H]\n",
    "      xvar = x.var(dim, keepdim=True) # xvar: [1, H]\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # xhat: [B, H]\n",
    "    self.out = self.gamma * xhat + self.beta  # out: [B, H]\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "module = BatchNorm1d(100)\n",
    "x = torch.randn(32, 100)\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xm=0.0000 xstd=1.0000\n"
     ]
    }
   ],
   "source": [
    "# we are normalizing columns (rows are batch samples, so we normalize each feature across the batch)\n",
    "xm = x[:,0].mean()\n",
    "xstd = x[:,0].std()\n",
    "print(f\"{xm=:.4f} {xstd=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "      # x: [B, H]\n",
    "    # calculate the forward pass\n",
    "    if x.ndim == 2:\n",
    "        dim = 1\n",
    "    elif x.ndim == 3:\n",
    "        dim = (1,2)\n",
    "    xmean = x.mean(dim, keepdim=True) # xmean: [1, H]\n",
    "    xvar = x.var(dim, keepdim=True) # xvar: [1, H]\n",
    "\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # xhat: [B, H]\n",
    "    self.out = self.gamma * xhat + self.beta  # out: [B, H]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100)\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xm=-0.0000 xstd=1.0000\n"
     ]
    }
   ],
   "source": [
    "# we are normalizing rows\n",
    "xm = x[0, :].mean()\n",
    "xstd = x[0, :].std()\n",
    "print(f\"{xm=:.4f} {xstd=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_gpt_scratch",
   "language": "python",
   "name": "kr_gpt_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
