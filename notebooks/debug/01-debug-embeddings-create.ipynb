{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/david.amat/Documents/david/pdf-search-llm-rag\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Get the absolute path of the current project directory\n",
    "project_dir = os.path.abspath('.')\n",
    "\n",
    "# Get the parent of the parent directory\n",
    "WORK_DIR = os.path.abspath(os.path.join(project_dir, '../../'))\n",
    "\n",
    "# Change the working directory to the parent of the parent directory\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "# Verify the change by printing the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_parquet(\"data/debug_read_pdf.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_processed = df_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SENTENCE_TRANSFORMER = 'all-MiniLM-L6-v2'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david.amat/Library/Caches/pypoetry/virtualenvs/pdf-search-llm-rag-mykPbGiu-py3.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer(\n",
    "    MODEL_SENTENCE_TRANSFORMER,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_number</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>reproduce the tables and figures in this paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scholarly works.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Attention Is All You Need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Ashish Vaswani∗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>109</td>\n",
       "      <td>&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>110</td>\n",
       "      <td>&lt;pad&gt;Figure 5: Many of the attention heads exh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>111</td>\n",
       "      <td>sentence. We give two such examples above, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>112</td>\n",
       "      <td>at layer 5 of 6. The heads clearly learned to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  page_number  paragraph  \\\n",
       "0    attention_is_all_you_need            1          1   \n",
       "1    attention_is_all_you_need            1          2   \n",
       "2    attention_is_all_you_need            1          3   \n",
       "3    attention_is_all_you_need            1          4   \n",
       "4    attention_is_all_you_need            1          5   \n",
       "..                         ...          ...        ...   \n",
       "826  attention_is_all_you_need           15        109   \n",
       "827  attention_is_all_you_need           15        110   \n",
       "828  attention_is_all_you_need           15        111   \n",
       "829  attention_is_all_you_need           15        112   \n",
       "830  attention_is_all_you_need           15        113   \n",
       "\n",
       "                                                  text  \n",
       "0    Provided proper attribution is provided, Googl...  \n",
       "1    reproduce the tables and figures in this paper...  \n",
       "2                                     scholarly works.  \n",
       "3                            Attention Is All You Need  \n",
       "4                                      Ashish Vaswani∗  \n",
       "..                                                 ...  \n",
       "826                                              <EOS>  \n",
       "827  <pad>Figure 5: Many of the attention heads exh...  \n",
       "828  sentence. We give two such examples above, fro...  \n",
       "829  at layer 5 of 6. The heads clearly learned to ...  \n",
       "830                                                 15  \n",
       "\n",
       "[831 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_text_processed[\"text\"].tolist()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 26/26 [00:00<00:00, 26.92it/s]\n"
     ]
    }
   ],
   "source": [
    "df_text_processed[\"embeddings\"] = pd.Series(\n",
    "    model.encode(df_text_processed[\"text\"], show_progress_bar=True).tolist(),\n",
    "    index=df_text_processed.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'context_id' with values ranging from 0 to the number of rows in the DataFrame\n",
    "df_text_processed['context_id'] = [*range(df_text_processed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_number</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>context_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>[-0.11509871482849121, 0.010262911207973957, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>reproduce the tables and figures in this paper...</td>\n",
       "      <td>[0.010889335535466671, 0.07457642257213593, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scholarly works.</td>\n",
       "      <td>[-0.07605524361133575, 0.06901659071445465, -0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Attention Is All You Need</td>\n",
       "      <td>[0.05313875898718834, -0.019583694636821747, -...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Ashish Vaswani∗</td>\n",
       "      <td>[-0.03129125386476517, 0.046448078006505966, 0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>109</td>\n",
       "      <td>&lt;EOS&gt;</td>\n",
       "      <td>[-0.015310936607420444, 0.07826308161020279, -...</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>110</td>\n",
       "      <td>&lt;pad&gt;Figure 5: Many of the attention heads exh...</td>\n",
       "      <td>[0.029949873685836792, -0.02654660865664482, 0...</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>111</td>\n",
       "      <td>sentence. We give two such examples above, fro...</td>\n",
       "      <td>[0.033357515931129456, -0.000603160064201802, ...</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>112</td>\n",
       "      <td>at layer 5 of 6. The heads clearly learned to ...</td>\n",
       "      <td>[-0.021467424929142, -0.008490338921546936, 0....</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>15</td>\n",
       "      <td>[-0.04739471524953842, 0.0998467281460762, -0....</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  page_number  paragraph  \\\n",
       "0    attention_is_all_you_need            1          1   \n",
       "1    attention_is_all_you_need            1          2   \n",
       "2    attention_is_all_you_need            1          3   \n",
       "3    attention_is_all_you_need            1          4   \n",
       "4    attention_is_all_you_need            1          5   \n",
       "..                         ...          ...        ...   \n",
       "826  attention_is_all_you_need           15        109   \n",
       "827  attention_is_all_you_need           15        110   \n",
       "828  attention_is_all_you_need           15        111   \n",
       "829  attention_is_all_you_need           15        112   \n",
       "830  attention_is_all_you_need           15        113   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Provided proper attribution is provided, Googl...   \n",
       "1    reproduce the tables and figures in this paper...   \n",
       "2                                     scholarly works.   \n",
       "3                            Attention Is All You Need   \n",
       "4                                      Ashish Vaswani∗   \n",
       "..                                                 ...   \n",
       "826                                              <EOS>   \n",
       "827  <pad>Figure 5: Many of the attention heads exh...   \n",
       "828  sentence. We give two such examples above, fro...   \n",
       "829  at layer 5 of 6. The heads clearly learned to ...   \n",
       "830                                                 15   \n",
       "\n",
       "                                            embeddings  context_id  \n",
       "0    [-0.11509871482849121, 0.010262911207973957, 0...           0  \n",
       "1    [0.010889335535466671, 0.07457642257213593, -0...           1  \n",
       "2    [-0.07605524361133575, 0.06901659071445465, -0...           2  \n",
       "3    [0.05313875898718834, -0.019583694636821747, -...           3  \n",
       "4    [-0.03129125386476517, 0.046448078006505966, 0...           4  \n",
       "..                                                 ...         ...  \n",
       "826  [-0.015310936607420444, 0.07826308161020279, -...         826  \n",
       "827  [0.029949873685836792, -0.02654660865664482, 0...         827  \n",
       "828  [0.033357515931129456, -0.000603160064201802, ...         828  \n",
       "829  [-0.021467424929142, -0.008490338921546936, 0....         829  \n",
       "830  [-0.04739471524953842, 0.0998467281460762, -0....         830  \n",
       "\n",
       "[831 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "print(f\"Embedding Dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopswork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy your Api Key (first register/login): https://c.app.hopsworks.ai/account/api/generated\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/963732\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs import embedding\n",
    "\n",
    "# Create the Embedding Index\n",
    "emb = embedding.EmbeddingIndex()\n",
    "\n",
    "emb.add_embedding(\n",
    "    \"embeddings\", \n",
    "    model.get_sentence_embedding_dimension(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/963732/fs/957507/fg/1102155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 831/831 | Elapsed Time: 00:09 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: documents_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/963732/jobs/named/documents_fg_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x2f20cd760>, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create the 'documents_fg' feature group\n",
    "documents_fg = fs.get_or_create_feature_group(\n",
    "    name=\"documents_fg\",\n",
    "    embedding_index=emb,\n",
    "    primary_key=['context_id'],\n",
    "    version=1,\n",
    "    description='Information from various files, presenting details like file names, source links, and structured text excerpts from different pages and paragraphs.',\n",
    "    online_enabled=True,\n",
    ")\n",
    "\n",
    "documents_fg.insert(df_text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/963732/fs/957507/fv/documents/version/1\n"
     ]
    }
   ],
   "source": [
    "# Get or create the 'documents' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"documents\",\n",
    "    version=1,\n",
    "    description='Chunked context for RAG system',\n",
    "    query=documents_fg.select([\"file_name\", \"page_number\", \"paragraph\", \"text\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Feature Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'documents' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='documents',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.32s) \n"
     ]
    }
   ],
   "source": [
    "# Get batch data from the feature view\n",
    "data = feature_view.get_batch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_number</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>entirely on self-attention to compute represen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>aligned RNNs or convolution. In the following ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>self-attention and discuss its advantages over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>3 Model Architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>Most competitive neural sequence transduction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>Here, the encoder maps an input sequence of sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>of continuous representations z= (z1, ..., z n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>sequence (y1, ..., y m)of symbols one element ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>[10], consuming the previously generated symbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  page_number  paragraph  \\\n",
       "237  attention_is_all_you_need            2         41   \n",
       "435  attention_is_all_you_need            2         42   \n",
       "580  attention_is_all_you_need            2         43   \n",
       "820  attention_is_all_you_need            2         44   \n",
       "111  attention_is_all_you_need            2         45   \n",
       "323  attention_is_all_you_need            2         46   \n",
       "386  attention_is_all_you_need            2         47   \n",
       "649  attention_is_all_you_need            2         48   \n",
       "770  attention_is_all_you_need            2         49   \n",
       "61   attention_is_all_you_need            2         50   \n",
       "\n",
       "                                                  text  \n",
       "237  entirely on self-attention to compute represen...  \n",
       "435  aligned RNNs or convolution. In the following ...  \n",
       "580  self-attention and discuss its advantages over...  \n",
       "820                               3 Model Architecture  \n",
       "111  Most competitive neural sequence transduction ...  \n",
       "323  Here, the encoder maps an input sequence of sy...  \n",
       "386  of continuous representations z= (z1, ..., z n...  \n",
       "649  sequence (y1, ..., y m)of symbols one element ...  \n",
       "770  [10], consuming the previously generated symbo...  \n",
       "61                                                   2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values([\"page_number\", \"paragraph\"], inplace=True)\n",
    "data[data[\"page_number\"] == 2].head(50).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_llm_rag",
   "language": "python",
   "name": "kr_llm_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
