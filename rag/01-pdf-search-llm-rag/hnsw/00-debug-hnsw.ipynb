{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate size of object in Python in MB\n",
    "def sizeof(obj):\n",
    "    objsize = sys.getsizeof(obj) / 1024 / 1024\n",
    "    print(f\"Size: {np.round(objsize,3)} MB\")\n",
    "    return objsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generate Random Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 0.488 MB\n"
     ]
    }
   ],
   "source": [
    "# Generate random embeddings\n",
    "def generate_random_embeddings(num_embeddings, dim):\n",
    "    embeddings = np.random.rand(num_embeddings, dim).astype(np.float32)\n",
    "    return embeddings\n",
    "\n",
    "# Add numpy seed for reproducibility\n",
    "np.random.seed(32)\n",
    "\n",
    "# Example: Create 1000 random embeddings with 128 dimensions\n",
    "num_embeddings = 1000\n",
    "dim = 128\n",
    "embeddings = generate_random_embeddings(num_embeddings, dim)\n",
    "_ = sizeof(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: HNSW Node and HNSW Class with Corrected Level Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define HNSW Node Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNSWNode:\n",
    "    def __init__(self, embedding, max_level, label=None):\n",
    "        self.embedding = embedding\n",
    "        self.label = label\n",
    "        # Initialize neighbors for all levels, even those higher than the node's assigned level\n",
    "        self.neighbors = {i: [] for i in range(max_level + 1)}\n",
    "\n",
    "    def add_neighbor(self, neighbor, level):\n",
    "        self.neighbors[level].append(neighbor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define HNSW Class with Corrected Level Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-Step Guide: Adding a New Node\n",
    "\n",
    "**1. Initialize Level for the New Node (_get_random_level):**\n",
    "\n",
    "The algorithm determines the level at which the new node will be placed. This level is chosen using a probabilistic approach, where higher levels are less likely to be chosen. The node will also be added to all levels below the selected level.\n",
    "\n",
    "2. Create the New Node (add_node):\n",
    "\n",
    "A new HNSWNode instance is created with the generated embedding and the determined level.\n",
    "\n",
    "3. Check for the First Node (add_node):\n",
    "\n",
    "If the HNSW structure is empty (i.e., no entry point exists), this new node becomes the entry_point, which is the starting node for all future searches. The process ends here for the first node.\n",
    "\n",
    "4. Insert Node into the Graph (_insert_node):\n",
    "\n",
    "If the graph already has an entry point, the algorithm begins the process of inserting the new node into the existing structure. This involves finding the best position for the new node by navigating through the graph from the top level down to the level of the new node.\n",
    "\n",
    "5. Search for the Best Insertion Point (_search_layer):\n",
    "\n",
    "Starting from the top level of the graph and the entry_point, the algorithm searches for the closest existing node to the new node’s embedding. It does this by comparing distances between the new node’s embedding and the embeddings of the neighbors at each level. The search continues until it finds the closest node or cannot improve the proximity by moving to another neighbor.\n",
    "\n",
    "6. Connect the New Node to the Nearest Neighbor (_connect_neighbors):\n",
    "\n",
    "Once the closest node is identified, the new node is connected to this node. This connection is mutual, meaning the new node also becomes a neighbor to the closest node.\n",
    "\n",
    "7. Prune Excess Neighbors (_prune_neighbors):\n",
    "\n",
    "If the number of neighbors exceeds a certain threshold (max_neighbours), the algorithm prunes the neighbors to keep only the closest ones. This ensures the graph remains manageable and efficient for searching.\n",
    "\n",
    "8. Add Node to All Appropriate Layers (add_node):\n",
    "\n",
    "Finally, the new node is added to the layers from the bottom (level 0) up to its assigned level. This ensures that the node is accessible from all levels below its assigned level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add numpy seed for reproducibility\n",
    "np.random.seed(32)\n",
    "\n",
    "class HNSW:\n",
    "    def __init__(self, max_level, max_neighbours=200, level_probability=0.5):\n",
    "        self.max_level = max_level\n",
    "        self.max_neighbours = max_neighbours\n",
    "        self.level_probability = level_probability\n",
    "        self.layers = {i: [] for i in range(max_level + 1)}\n",
    "        self.entry_point = None\n",
    "\n",
    "    # ------------------------ #\n",
    "    #    Adding Node\n",
    "    # ------------------------ #\n",
    "    def add_node(self, embedding, label=None):\n",
    "        level = self._get_random_level()\n",
    "        new_node = HNSWNode(embedding, self.max_level, label=label)\n",
    "        if self.entry_point is None:\n",
    "            self.entry_point = new_node\n",
    "        else:\n",
    "            self._insert_node(new_node, level)\n",
    "        for l in range(level + 1):\n",
    "            self.layers[l].append(new_node)\n",
    "\n",
    "    def _get_random_level(self):\n",
    "        level = 0\n",
    "        while np.random.rand() < self.level_probability and level < self.max_level:\n",
    "            level += 1\n",
    "        return level\n",
    "\n",
    "    # ------------------------------------------------ #\n",
    "    #    Adding Node when Entrypoint is not Null\n",
    "    # ------------------------------------------------ #\n",
    "    def _insert_node(self, new_node, level):\n",
    "        current_node = self.entry_point\n",
    "        # list: [level_new_node, level_new_node-1, ..., 0]\n",
    "        for l in reversed(range(level + 1)):\n",
    "            current_node = self._search_layer(new_node.embedding, current_node, l)\n",
    "            self._connect_neighbors(new_node, current_node, l)\n",
    "\n",
    "    def _search_layer(self, query, entry_point, layer):\n",
    "        current_node = entry_point\n",
    "        while True:\n",
    "            neighbors = current_node.neighbors[layer]\n",
    "            \n",
    "            # Return the closest HNSWNode in that layer otherwise None\n",
    "            closest = self._find_closest(query, neighbors)\n",
    "            \n",
    "            # if in that level there is no neighbor, then break\n",
    "            # if the distance of the query to the closest neighbor is greater than the distance of the query to the current node, then break\n",
    "            if closest is None or self._distance(query, closest.embedding) >= self._distance(query, current_node.embedding):\n",
    "                # If True (Neighbor Not Closer) then break\n",
    "                break\n",
    "            current_node = closest\n",
    "        return current_node\n",
    "\n",
    "    def _connect_neighbors(self, new_node, closest_node, level):\n",
    "        if new_node.label != closest_node.label:\n",
    "            closest_node.add_neighbor(new_node, level)\n",
    "            new_node.add_neighbor(closest_node, level)\n",
    "        if len(new_node.neighbors[level]) > self.max_neighbours:\n",
    "            new_node.neighbors[level] = self._prune_neighbors(new_node.neighbors[level], new_node.embedding)\n",
    "\n",
    "    def _prune_neighbors(self, neighbors, embedding):\n",
    "        distances = self._distance_matrix(embedding, [neighbor.embedding for neighbor in neighbors])\n",
    "        pruned_indices = np.argsort(distances)[:self.max_neighbours]\n",
    "        return [neighbors[i] for i in pruned_indices]\n",
    "\n",
    "    def _find_closest(self, query, neighbors):\n",
    "        if not neighbors:\n",
    "            return None\n",
    "        neighbor_embeddings = np.array([neighbor.embedding for neighbor in neighbors])\n",
    "        distances = self._distance_matrix(query, neighbor_embeddings)\n",
    "        closest_idx = np.argmin(distances)\n",
    "        return neighbors[closest_idx]\n",
    "\n",
    "    def _distance_matrix(self, vec, matrix):\n",
    "        # Calculate Euclidean distance in a vectorized manner\n",
    "        return np.linalg.norm(matrix - vec, axis=1)\n",
    "\n",
    "    def _distance(self, vec1, vec2):\n",
    "        return np.linalg.norm(vec1 - vec2)\n",
    "    \n",
    "    # ------------------------------------------------ #\n",
    "    #    Inference\n",
    "    # ------------------------------------------------ #\n",
    "    def search_knn(self, query_embedding, k):\n",
    "        # Start the search from the entry point at the top level\n",
    "        current_node = self.entry_point\n",
    "        for level in reversed(range(self.max_level + 1)):\n",
    "            current_node = self._search_layer(query_embedding, current_node, level)\n",
    "        \n",
    "        # Now perform a search in the bottom layer to find the top K nearest neighbors\n",
    "        neighbors = current_node.neighbors[0]  # Start with neighbors in the bottom level (level 0)\n",
    "        candidates = [current_node] + neighbors  # Include the current node itself\n",
    "        \n",
    "        # Calculate distances from the query to all candidates\n",
    "        distances = [self._distance(query_embedding, node.embedding) for node in candidates]\n",
    "        \n",
    "        # Sort candidates by distance\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        \n",
    "        # Select the top K closest nodes\n",
    "        top_k_indices = sorted_indices[:k]\n",
    "        \n",
    "        # Return the top K closest nodes (or embeddings)\n",
    "        top_k_nodes = [candidates[i] for i in top_k_indices]\n",
    "        \n",
    "        return top_k_nodes\n",
    "\n",
    "    \n",
    "    \n",
    "class HNSW_V2:\n",
    "    \"\"\"\n",
    "    V2: we use multiple entry points to search in parallel in a given layer\n",
    "    \"\"\"\n",
    "    def __init__(self, max_level, max_neighbours=200, level_probability=0.5):\n",
    "        self.max_level = max_level\n",
    "        self.max_neighbours = max_neighbours\n",
    "        self.level_probability = level_probability\n",
    "        self.layers = {i: [] for i in range(max_level + 1)}\n",
    "        self.entry_point = None\n",
    "\n",
    "    def add_node(self, embedding, label=None):\n",
    "        level = self._get_random_level()\n",
    "        new_node = HNSWNode(embedding, self.max_level, label=label)\n",
    "        if self.entry_point is None:\n",
    "            self.entry_point = new_node  # Set entry_point only when it's None\n",
    "        self._insert_node(new_node, level)\n",
    "        for l in range(level + 1):\n",
    "            self.layers[l].append(new_node)\n",
    "\n",
    "\n",
    "    def _get_random_level(self):\n",
    "        level = 0\n",
    "        while np.random.rand() < self.level_probability and level < self.max_level:\n",
    "            level += 1\n",
    "        return level\n",
    "\n",
    "    def _insert_node(self, new_node, level):\n",
    "        current_node = self.entry_point\n",
    "        for l in reversed(range(level + 1)):\n",
    "            current_node = self._search_layer(new_node.embedding, current_node, l)\n",
    "            self._connect_neighbors(new_node, current_node, l)\n",
    "\n",
    "    def _search_layer(self, query, entry_point, layer):\n",
    "        # Select 3 entry points with the most neighbors\n",
    "        entry_points = self._select_top_entry_points(layer)\n",
    "        \n",
    "        # Perform searches from each entry point\n",
    "        candidates = []\n",
    "        for ep in entry_points:\n",
    "            result = self._single_search_layer(query, ep, layer)\n",
    "            if result is not None:\n",
    "                candidates.append(result)\n",
    "\n",
    "        # Check if candidates list is empty\n",
    "        if not candidates:\n",
    "            return entry_point  # or return None, depending on the desired behavior\n",
    "        \n",
    "        # Find the closest node among all candidates\n",
    "        closest = min(candidates, key=lambda node: self._distance(query, node.embedding))\n",
    "        return closest\n",
    "\n",
    "\n",
    "    def _select_top_entry_points(self, layer):\n",
    "        # Sort nodes in the layer by the number of neighbors, in descending order\n",
    "        sorted_nodes = sorted(self.layers[layer], key=lambda node: len(node.neighbors[layer]), reverse=True)\n",
    "        \n",
    "        # Select the top 3 nodes with the most neighbors\n",
    "        top_entry_points = sorted_nodes[:3]\n",
    "        \n",
    "        return top_entry_points\n",
    "\n",
    "    def _single_search_layer(self, query, entry_point, layer):\n",
    "        current_node = entry_point\n",
    "        while True:\n",
    "            neighbors = current_node.neighbors[layer]\n",
    "            closest = self._find_closest(query, neighbors)\n",
    "            if closest is None or self._distance(query, closest.embedding) >= self._distance(query, current_node.embedding):\n",
    "                break\n",
    "            current_node = closest\n",
    "        return current_node\n",
    "\n",
    "    def _connect_neighbors(self, new_node, closest_node, level):\n",
    "        if new_node.label != closest_node.label:\n",
    "            closest_node.add_neighbor(new_node, level)\n",
    "            new_node.add_neighbor(closest_node, level)\n",
    "        if len(new_node.neighbors[level]) > self.max_neighbours:\n",
    "            new_node.neighbors[level] = self._prune_neighbors(new_node.neighbors[level], new_node.embedding)\n",
    "\n",
    "    def _prune_neighbors(self, neighbors, embedding):\n",
    "        distances = self._distance_matrix(embedding, [neighbor.embedding for neighbor in neighbors])\n",
    "        pruned_indices = np.argsort(distances)[:self.max_neighbours]\n",
    "        return [neighbors[i] for i in pruned_indices]\n",
    "\n",
    "    def _find_closest(self, query, neighbors):\n",
    "        if not neighbors:\n",
    "            return None\n",
    "        neighbor_embeddings = np.array([neighbor.embedding for neighbor in neighbors])\n",
    "        distances = self._distance_matrix(query, neighbor_embeddings)\n",
    "        closest_idx = np.argmin(distances)\n",
    "        return neighbors[closest_idx]\n",
    "\n",
    "    def _distance_matrix(self, vec, matrix):\n",
    "        return np.linalg.norm(matrix - vec, axis=1)\n",
    "\n",
    "    def _distance(self, vec1, vec2):\n",
    "        return np.linalg.norm(vec1 - vec2)\n",
    "    \n",
    "    def search_knn(self, query_embedding, k):\n",
    "        # Start the search from the top level using multiple entry points\n",
    "        current_candidates = []\n",
    "        \n",
    "        for level in reversed(range(self.max_level + 1)):\n",
    "            # Get the top 3 entry points with the most neighbors at the current level\n",
    "            entry_points = self._select_top_entry_points(level)\n",
    "            \n",
    "            # Perform searches from each entry point and collect candidates\n",
    "            level_candidates = []\n",
    "            for entry_point in entry_points:\n",
    "                candidate = self._single_search_layer(query_embedding, entry_point, level)\n",
    "                if candidate:\n",
    "                    level_candidates.append(candidate)\n",
    "            \n",
    "            # Merge level candidates into the current candidates\n",
    "            current_candidates.extend(level_candidates)\n",
    "        \n",
    "        # Remove duplicates from candidates\n",
    "        current_candidates = list(set(current_candidates))\n",
    "        \n",
    "        # Perform a final selection of the top K nearest neighbors from the bottom level\n",
    "        if current_candidates:\n",
    "            distances = [self._distance(query_embedding, node.embedding) for node in current_candidates]\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            top_k_nodes = [current_candidates[i] for i in sorted_indices[:k]]\n",
    "        else:\n",
    "            top_k_nodes = []\n",
    "\n",
    "        return top_k_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Debug V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 10.4 ms, total: 138 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "hnsw = HNSW(max_level=3)\n",
    "for i, emb in enumerate(embeddings):\n",
    "    hnsw.add_node(emb, label=f\"emb{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fake embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embf = 0.5*embeddings[0] + 0.5*embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "hnsw.add_node(embf, label=\"embf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Debug V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 847 ms, sys: 19.8 ms, total: 867 ms\n",
      "Wall time: 904 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "hnsw2 = HNSW_V2(max_level=3)\n",
    "for i, emb in enumerate(embeddings):\n",
    "    hnsw2.add_node(emb, label=f\"emb{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fake embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embf = 0.5*embeddings[0] + 0.5*embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "hnsw2.add_node(embf, label=\"embf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Finding K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 0.244 MB\n"
     ]
    }
   ],
   "source": [
    "# Add numpy seed for reproducibility\n",
    "np.random.seed(63)\n",
    "\n",
    "# Example: Create 1000 random embeddings with 128 dimensions\n",
    "num_embeddings = 500\n",
    "dim = 128\n",
    "test_embeddings = generate_random_embeddings(num_embeddings, dim)\n",
    "_ = sizeof(test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change:\n",
    "1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import recall_score, precision_score, label_ranking_average_precision_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "import numpy as np\n",
    "\n",
    "def mean_reciprocal_rank(y_true, y_pred):\n",
    "    mrrs = []\n",
    "    for true_labels, pred_scores in zip(y_true, y_pred):\n",
    "        # Rank predictions in descending order\n",
    "        ranks = rankdata(-pred_scores, method='ordinal')\n",
    "        # Get the rank of the true label\n",
    "        true_rank = ranks[np.argmax(true_labels)]\n",
    "        # Calculate reciprocal rank\n",
    "        mrrs.append(1.0 / true_rank)\n",
    "    return np.mean(mrrs)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "y_true = np.array([[0, 0, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
    "y_pred = np.array([[0.1, 0.2, 0.9, 0.4, 0.3], [0.05, 0.1, 0.6, 0.8, 0.4]])\n",
    "mrr = mean_reciprocal_rank(y_true, y_pred)\n",
    "print(f\"MRR: {mrr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exact KNN with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "K = 10  # Set the value of K\n",
    "dim = 128\n",
    "\n",
    "# Initialize the NearestNeighbors model from scikit-learn\n",
    "knn_model = NearestNeighbors(n_neighbors=K, algorithm='brute', metric='euclidean')\n",
    "\n",
    "# Fit the model to the test embeddings\n",
    "knn_model.fit(embeddings)\n",
    "\n",
    "# Perform exact KNN search\n",
    "start_time_knn = time.time()\n",
    "distances, indices = knn_model.kneighbors(test_embeddings)\n",
    "knn_exact_time = time.time() - start_time_knn\n",
    "\n",
    "# Store the exact KNN results as the real ranking of node labels\n",
    "exact_knn_labels = [indices[i] for i in range(len(test_embeddings))]\n",
    "exact_knn_distances = [distances[i] for i in range(len(test_embeddings))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HNSW KNN Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_hnsw(hnsw_class, embeddings, test_embeddings, K):\n",
    "    \"\"\"\n",
    "    Perform KNN search for each embedding using the given HNSW class (HNSW or HNSW_V2).\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    # Initialize the HNSW model\n",
    "    hnsw = hnsw_class(max_level=3)\n",
    "\n",
    "    # Adding nodes to HNSW\n",
    "    start_time_hnsw_add = time.time()\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        hnsw.add_node(emb, label=f\"emb{i}\")\n",
    "    hnsw_add_time = time.time() - start_time_hnsw_add\n",
    "\n",
    "    # Perform HNSW search_knn for each test embedding\n",
    "    hnsw_knn_labels = []\n",
    "    start_time_hnsw_search = time.time()\n",
    "    for emb in test_embeddings:\n",
    "        top_k_nodes = hnsw.search_knn(emb, k=K)\n",
    "        hnsw_knn_labels.append([int(node.label.replace('emb', '')) for node in top_k_nodes])\n",
    "    hnsw_search_time = time.time() - start_time_hnsw_search\n",
    "\n",
    "    return hnsw_knn_labels, hnsw_add_time, hnsw_search_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark HNSW (V1)\n",
    "hnsw_v1_labels, hnsw_v1_add_time, hnsw_v1_search_time = benchmark_hnsw(HNSW, embeddings, test_embeddings, K)\n",
    "\n",
    "# Benchmark HNSW_V2\n",
    "hnsw_v2_labels, hnsw_v2_add_time, hnsw_v2_search_time = benchmark_hnsw(HNSW_V2, embeddings, test_embeddings, K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ranking Metrics: Recall@K, Precision@K, MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for ranking metrics\n",
    "def recall_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual[:k])\n",
    "    predicted_set = set(predicted[:k])\n",
    "    return len(actual_set & predicted_set) / len(actual_set)\n",
    "\n",
    "def precision_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual[:k])\n",
    "    predicted_set = set(predicted[:k])\n",
    "    return len(actual_set & predicted_set) / k\n",
    "\n",
    "def mean_reciprocal_rank(actual, predicted):\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "def calculate_metrics(exact_labels, hnsw_labels, K):\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    mrr_scores = []\n",
    "\n",
    "    for i in range(num_embeddings):\n",
    "        recall = recall_at_k(exact_labels[i], hnsw_labels[i], K)\n",
    "        precision = precision_at_k(exact_labels[i], hnsw_labels[i], K)\n",
    "        mrr = mean_reciprocal_rank(exact_labels[i], hnsw_labels[i])\n",
    "\n",
    "        recall_scores.append(recall)\n",
    "        precision_scores.append(precision)\n",
    "        mrr_scores.append(mrr)\n",
    "\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_mrr = np.mean(mrr_scores)\n",
    "\n",
    "    return average_recall, average_precision, average_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Pandas DataFrame for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for HNSW (V1)\n",
    "v1_recall, v1_precision, v1_mrr = calculate_metrics(exact_knn_labels, hnsw_v1_labels, K)\n",
    "\n",
    "# Calculate metrics for HNSW_V2\n",
    "v2_recall, v2_precision, v2_mrr = calculate_metrics(exact_knn_labels, hnsw_v2_labels, K)\n",
    "\n",
    "\n",
    "\n",
    "# Create a pandas DataFrame to store the results\n",
    "benchmark_df = pd.DataFrame({\n",
    "    'method': ['HNSW_V1', 'HNSW_V2'],\n",
    "    'num_embeddings': [num_embeddings, num_embeddings],\n",
    "    'embedding_dim': [dim, dim],\n",
    "    'average_recall': [v1_recall, v2_recall],\n",
    "    'average_precision': [v1_precision, v2_precision],\n",
    "    'average_mrr': [v1_mrr, v2_mrr],\n",
    "    'add_time': [hnsw_v1_add_time, hnsw_v2_add_time],\n",
    "    'search_time': [hnsw_v1_search_time, hnsw_v2_search_time],\n",
    "    'knn_exact_search_time': [knn_exact_time, knn_exact_time]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>num_embeddings</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>average_recall</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>average_mrr</th>\n",
       "      <th>add_time</th>\n",
       "      <th>search_time</th>\n",
       "      <th>knn_exact_search_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSW_V1</td>\n",
       "      <td>500</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122691</td>\n",
       "      <td>0.110658</td>\n",
       "      <td>0.007073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HNSW_V2</td>\n",
       "      <td>500</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958108</td>\n",
       "      <td>1.296570</td>\n",
       "      <td>0.007073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  num_embeddings  embedding_dim  average_recall  average_precision  \\\n",
       "0  HNSW_V1             500            128          0.0396             0.0396   \n",
       "1  HNSW_V2             500            128          0.2720             0.2720   \n",
       "\n",
       "   average_mrr  add_time  search_time  knn_exact_search_time  \n",
       "0          1.0  0.122691     0.110658               0.007073  \n",
       "1          1.0  0.958108     1.296570               0.007073  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_llm_rag_v2",
   "language": "python",
   "name": "kr_llm_rag_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
