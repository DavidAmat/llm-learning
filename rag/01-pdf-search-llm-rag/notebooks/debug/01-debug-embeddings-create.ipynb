{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/david.amat/Documents/david/pdf-search-llm-rag\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Get the absolute path of the current project directory\n",
    "project_dir = os.path.abspath('.')\n",
    "\n",
    "# Get the parent of the parent directory\n",
    "WORK_DIR = os.path.abspath(os.path.join(project_dir, '../../'))\n",
    "\n",
    "# Change the working directory to the parent of the parent directory\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "# Verify the change by printing the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_parquet(\"data/debug_read_pdf.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_processed = df_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david.amat/Library/Caches/pypoetry/virtualenvs/pdf-search-llm-rag-mykPbGiu-py3.9/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SENTENCE_TRANSFORMER = 'all-MiniLM-L6-v2'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david.amat/Library/Caches/pypoetry/virtualenvs/pdf-search-llm-rag-mykPbGiu-py3.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer(\n",
    "    MODEL_SENTENCE_TRANSFORMER,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_number</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Attention Is All You Need\\nAshish Vaswani∗\\nGo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>∗Equal contribution. Listing order is random. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>†Work performed while at Google Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>‡Work performed while at Google Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;\\nInput-Input Layer5\\nThe\\nLaw\\nwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;Figure 5: Many of the attention he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  page_number  paragraph  \\\n",
       "0    attention_is_all_you_need            1          1   \n",
       "1    attention_is_all_you_need            1          2   \n",
       "2    attention_is_all_you_need            1          3   \n",
       "3    attention_is_all_you_need            1          4   \n",
       "4    attention_is_all_you_need            1          5   \n",
       "..                         ...          ...        ...   \n",
       "138  attention_is_all_you_need           15          2   \n",
       "139  attention_is_all_you_need           15          3   \n",
       "140  attention_is_all_you_need           15          4   \n",
       "141  attention_is_all_you_need           15          5   \n",
       "142  attention_is_all_you_need           15          6   \n",
       "\n",
       "                                                  text  \n",
       "0    Provided proper attribution is provided, Googl...  \n",
       "1    Attention Is All You Need\\nAshish Vaswani∗\\nGo...  \n",
       "2    ∗Equal contribution. Listing order is random. ...  \n",
       "3                †Work performed while at Google Brain  \n",
       "4             ‡Work performed while at Google Research  \n",
       "..                                                 ...  \n",
       "138  <EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...  \n",
       "139  <EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwi...  \n",
       "140  <EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...  \n",
       "141  <EOS>\\n<pad>Figure 5: Many of the attention he...  \n",
       "142                                                 15  \n",
       "\n",
       "[143 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_text_processed[\"text\"].tolist()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:01<00:00,  4.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df_text_processed[\"embeddings\"] = pd.Series(\n",
    "    model.encode(df_text_processed[\"text\"], show_progress_bar=True).tolist(),\n",
    "    index=df_text_processed.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'context_id' with values ranging from 0 to the number of rows in the DataFrame\n",
    "df_text_processed['context_id'] = [*range(df_text_processed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_number</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>context_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>[-0.017848478630185127, 0.014465652406215668, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Attention Is All You Need\\nAshish Vaswani∗\\nGo...</td>\n",
       "      <td>[-0.07263379544019699, -0.1257372349500656, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>∗Equal contribution. Listing order is random. ...</td>\n",
       "      <td>[-0.08534739911556244, -0.09007889777421951, -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>†Work performed while at Google Brain</td>\n",
       "      <td>[-0.0912894532084465, -0.0209952425211668, 0.0...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>‡Work performed while at Google Research</td>\n",
       "      <td>[-0.11088573932647705, 0.03885276988148689, 0....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...</td>\n",
       "      <td>[-0.04332689568400383, 0.022461799904704094, -...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;\\nInput-Input Layer5\\nThe\\nLaw\\nwi...</td>\n",
       "      <td>[-0.06781154125928879, -0.0022821910679340363,...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...</td>\n",
       "      <td>[-0.04332689568400383, 0.022461799904704094, -...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;EOS&gt;\\n&lt;pad&gt;Figure 5: Many of the attention he...</td>\n",
       "      <td>[0.019566060975193977, -0.022429874166846275, ...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>attention_is_all_you_need</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>[-0.047394752502441406, 0.09984666854143143, -...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  page_number  paragraph  \\\n",
       "0    attention_is_all_you_need            1          1   \n",
       "1    attention_is_all_you_need            1          2   \n",
       "2    attention_is_all_you_need            1          3   \n",
       "3    attention_is_all_you_need            1          4   \n",
       "4    attention_is_all_you_need            1          5   \n",
       "..                         ...          ...        ...   \n",
       "138  attention_is_all_you_need           15          2   \n",
       "139  attention_is_all_you_need           15          3   \n",
       "140  attention_is_all_you_need           15          4   \n",
       "141  attention_is_all_you_need           15          5   \n",
       "142  attention_is_all_you_need           15          6   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Provided proper attribution is provided, Googl...   \n",
       "1    Attention Is All You Need\\nAshish Vaswani∗\\nGo...   \n",
       "2    ∗Equal contribution. Listing order is random. ...   \n",
       "3                †Work performed while at Google Brain   \n",
       "4             ‡Work performed while at Google Research   \n",
       "..                                                 ...   \n",
       "138  <EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...   \n",
       "139  <EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwi...   \n",
       "140  <EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfe...   \n",
       "141  <EOS>\\n<pad>Figure 5: Many of the attention he...   \n",
       "142                                                 15   \n",
       "\n",
       "                                            embeddings  context_id  \n",
       "0    [-0.017848478630185127, 0.014465652406215668, ...           0  \n",
       "1    [-0.07263379544019699, -0.1257372349500656, 0....           1  \n",
       "2    [-0.08534739911556244, -0.09007889777421951, -...           2  \n",
       "3    [-0.0912894532084465, -0.0209952425211668, 0.0...           3  \n",
       "4    [-0.11088573932647705, 0.03885276988148689, 0....           4  \n",
       "..                                                 ...         ...  \n",
       "138  [-0.04332689568400383, 0.022461799904704094, -...         138  \n",
       "139  [-0.06781154125928879, -0.0022821910679340363,...         139  \n",
       "140  [-0.04332689568400383, 0.022461799904704094, -...         140  \n",
       "141  [0.019566060975193977, -0.022429874166846275, ...         141  \n",
       "142  [-0.047394752502441406, 0.09984666854143143, -...         142  \n",
       "\n",
       "[143 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "print(f\"Embedding Dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_processed.to_parquet(\"data/debug_embeddings_create.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_llm_rag",
   "language": "python",
   "name": "kr_llm_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
